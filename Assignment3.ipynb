{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3w5Qx_pXB5C"
      },
      "source": [
        "#**Question 1**\n",
        "\n",
        "Design a convolutional neural network in Keras of at least 10 convolutional layers. Use the MNIST dataset  for  evaluation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az3A027JzjOE",
        "outputId": "5099dfbf-910d-4440-f682-991a6ec117e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 1, 28, 28) train samples\n",
            "(10000, 1, 28, 28) test samples\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.utils import np_utils\n",
        "\n",
        "num_classes = 10 \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "x_train = x_train[:, np.newaxis, :, :]\n",
        "x_test = x_test[:, np.newaxis, :, :]\n",
        "print(x_train.shape, 'train samples')\n",
        "print(x_test.shape, 'test samples')\n",
        "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zq1gWrV8zmBQ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "def get_model1(input_shape, num_classes):\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Conv2D(3, kernel_size=3, padding=\"same\", input_shape=input_shape),\n",
        "            layers.Conv2D(4, kernel_size=3, padding=\"same\"),\n",
        "            layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "            layers.Conv2D(5, kernel_size=3, padding=\"same\"),\n",
        "            layers.Conv2D(6, kernel_size=3, padding=\"same\"),\n",
        "            layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "            layers.Conv2D(7, kernel_size=3, padding=\"same\"),\n",
        "            layers.Conv2D(8, kernel_size=3, padding=\"same\"),\n",
        "            layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "            layers.Conv2D(9, kernel_size=3, padding=\"same\"),\n",
        "            layers.Conv2D(10, kernel_size=3, padding=\"same\"),\n",
        "            layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "            layers.Conv2D(11, kernel_size=3, padding=\"same\"),\n",
        "            layers.Conv2D(12, kernel_size=3, padding=\"same\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(num_classes, activation=\"softmax\")\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "def get_model2(input_shape, num_classes):\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "                layers.Conv2D(12, kernel_size=3, padding=\"same\", input_shape=input_shape),\n",
        "                layers.Conv2D(11, kernel_size=3, padding=\"same\"),\n",
        "                layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.Conv2D(10, kernel_size=3, padding=\"same\"),\n",
        "                layers.Conv2D(9, kernel_size=3, padding=\"same\"),\n",
        "                layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.Conv2D(8, kernel_size=3, padding=\"same\"),\n",
        "                layers.Conv2D(7, kernel_size=3, padding=\"same\"),\n",
        "                layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.Conv2D(6, kernel_size=3, padding=\"same\"),\n",
        "                layers.Conv2D(5, kernel_size=3, padding=\"same\"),\n",
        "                layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.Conv2D(4, kernel_size=3, padding=\"same\"),\n",
        "                layers.Conv2D(3, kernel_size=3, padding=\"same\"),\n",
        "                layers.Flatten(),\n",
        "                layers.Dense(num_classes, activation=\"softmax\")\n",
        "        ]\n",
        "\n",
        "    )\n",
        "\n",
        "    return model\n",
        "def get_model3(input_shape, num_classes):\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "                layers.Conv2D(3, kernel_size=3, padding=\"same\", input_shape=input_shape),\n",
        "                layers.Conv2D(4, kernel_size=3, padding=\"same\"),\n",
        "                layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.Conv2D(5, kernel_size=3, padding=\"same\"),\n",
        "                layers.Conv2D(6, kernel_size=3, padding=\"same\"),\n",
        "                layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.Conv2D(7, kernel_size=3, padding=\"same\"),\n",
        "                layers.Conv2D(8, kernel_size=3, padding=\"same\"),\n",
        "                layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.Conv2D(9, kernel_size=3, padding=\"same\"),\n",
        "                layers.Conv2D(10, kernel_size=3, padding=\"same\"),\n",
        "                layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.Conv2D(11, kernel_size=3, padding=\"same\"),\n",
        "                layers.Conv2D(12, kernel_size=3, padding=\"same\"),\n",
        "                layers.Flatten(),\n",
        "                layers.Dense(num_classes, activation=\"softmax\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    \n",
        "    return model      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhj4mrIcWoOk"
      },
      "source": [
        "#Model 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBFew_XCjLmz",
        "outputId": "3385bbe8-1759-48f0-cf8b-5b6593b410ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_63 (Conv2D)          (None, 1, 28, 3)          759       \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 1, 28, 4)          112       \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 1, 14, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 1, 14, 5)          185       \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 1, 14, 6)          276       \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 1, 7, 6)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 1, 7, 7)           385       \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 1, 7, 8)           512       \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 1, 4, 8)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 1, 4, 9)           657       \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 1, 4, 10)          820       \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 1, 2, 10)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 1, 2, 11)          1001      \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 1, 2, 12)          1200      \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                250       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,157\n",
            "Trainable params: 6,157\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 2.0162 - accuracy: 0.2548 - val_loss: 1.4317 - val_accuracy: 0.4766\n",
            "Epoch 2/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 1.1189 - accuracy: 0.6043 - val_loss: 0.8395 - val_accuracy: 0.7236\n",
            "Epoch 3/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.6180 - accuracy: 0.7970 - val_loss: 0.4676 - val_accuracy: 0.8515\n",
            "Epoch 4/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.4624 - accuracy: 0.8520 - val_loss: 0.4462 - val_accuracy: 0.8595\n",
            "Epoch 5/25\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.4010 - accuracy: 0.8732 - val_loss: 0.3863 - val_accuracy: 0.8733\n",
            "Epoch 6/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.3699 - accuracy: 0.8843 - val_loss: 0.3146 - val_accuracy: 0.8963\n",
            "Epoch 7/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.3427 - accuracy: 0.8922 - val_loss: 0.3634 - val_accuracy: 0.8839\n",
            "Epoch 8/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.3231 - accuracy: 0.8986 - val_loss: 0.2997 - val_accuracy: 0.9082\n",
            "Epoch 9/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.3080 - accuracy: 0.9055 - val_loss: 0.2948 - val_accuracy: 0.9028\n",
            "Epoch 10/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2943 - accuracy: 0.9094 - val_loss: 0.3051 - val_accuracy: 0.9058\n",
            "Epoch 11/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2833 - accuracy: 0.9129 - val_loss: 0.2899 - val_accuracy: 0.9039\n",
            "Epoch 12/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2676 - accuracy: 0.9180 - val_loss: 0.3203 - val_accuracy: 0.8920\n",
            "Epoch 13/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2602 - accuracy: 0.9194 - val_loss: 0.2338 - val_accuracy: 0.9248\n",
            "Epoch 14/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2476 - accuracy: 0.9238 - val_loss: 0.2738 - val_accuracy: 0.9141\n",
            "Epoch 15/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2425 - accuracy: 0.9250 - val_loss: 0.2415 - val_accuracy: 0.9242\n",
            "Epoch 16/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2341 - accuracy: 0.9277 - val_loss: 0.2232 - val_accuracy: 0.9317\n",
            "Epoch 17/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2293 - accuracy: 0.9289 - val_loss: 0.2186 - val_accuracy: 0.9312\n",
            "Epoch 18/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2230 - accuracy: 0.9310 - val_loss: 0.2168 - val_accuracy: 0.9348\n",
            "Epoch 19/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2167 - accuracy: 0.9336 - val_loss: 0.2087 - val_accuracy: 0.9368\n",
            "Epoch 20/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2117 - accuracy: 0.9345 - val_loss: 0.2087 - val_accuracy: 0.9348\n",
            "Epoch 21/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2099 - accuracy: 0.9351 - val_loss: 0.2791 - val_accuracy: 0.9116\n",
            "Epoch 22/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2058 - accuracy: 0.9359 - val_loss: 0.2283 - val_accuracy: 0.9277\n",
            "Epoch 23/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.2022 - accuracy: 0.9375 - val_loss: 0.2066 - val_accuracy: 0.9365\n",
            "Epoch 24/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.1992 - accuracy: 0.9381 - val_loss: 0.1984 - val_accuracy: 0.9383\n",
            "Epoch 25/25\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.1950 - accuracy: 0.9391 - val_loss: 0.2860 - val_accuracy: 0.9132\n",
            "Accuracy: 0.11349999904632568\n"
          ]
        }
      ],
      "source": [
        "rows, col = 28, 28 \n",
        "input_shape = (1, rows, col)\n",
        "epochs = 25\n",
        "verbose = 0\n",
        "optimizer = SGD()\n",
        "model = get_model1(input_shape, num_classes)\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.fit(x_train, Y_train, batch_size=256, epochs=epochs, validation_split=0.2)\n",
        "result = model.evaluate(x_test, Y_test, verbose=verbose)\n",
        "print('Accuracy:', result[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g_av_zEWvTs"
      },
      "source": [
        "#Model 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz9XAD50WyC-",
        "outputId": "f4e9b7b0-e8ee-4947-b3df-12d0ae21fa0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_73 (Conv2D)          (None, 1, 28, 12)         3036      \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 1, 28, 11)         1199      \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 1, 14, 11)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_75 (Conv2D)          (None, 1, 14, 10)         1000      \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 1, 14, 9)          819       \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 1, 7, 9)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 1, 7, 8)           656       \n",
            "                                                                 \n",
            " conv2d_78 (Conv2D)          (None, 1, 7, 7)           511       \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 1, 4, 7)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 1, 4, 6)           384       \n",
            "                                                                 \n",
            " conv2d_80 (Conv2D)          (None, 1, 4, 5)           275       \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 1, 2, 5)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 1, 2, 4)           184       \n",
            "                                                                 \n",
            " conv2d_82 (Conv2D)          (None, 1, 2, 3)           111       \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                70        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,245\n",
            "Trainable params: 8,245\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.7409 - accuracy: 0.7696 - val_loss: 0.3604 - val_accuracy: 0.8957\n",
            "Epoch 2/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.2983 - accuracy: 0.9155 - val_loss: 0.2857 - val_accuracy: 0.9183\n",
            "Epoch 3/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.2245 - accuracy: 0.9351 - val_loss: 0.2297 - val_accuracy: 0.9325\n",
            "Epoch 4/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1912 - accuracy: 0.9444 - val_loss: 0.1760 - val_accuracy: 0.9474\n",
            "Epoch 5/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1729 - accuracy: 0.9490 - val_loss: 0.1631 - val_accuracy: 0.9528\n",
            "Epoch 6/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1585 - accuracy: 0.9536 - val_loss: 0.1579 - val_accuracy: 0.9532\n",
            "Epoch 7/25\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.1517 - accuracy: 0.9557 - val_loss: 0.1528 - val_accuracy: 0.9542\n",
            "Epoch 8/25\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.1432 - accuracy: 0.9570 - val_loss: 0.1512 - val_accuracy: 0.9540\n",
            "Epoch 9/25\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.1352 - accuracy: 0.9605 - val_loss: 0.1352 - val_accuracy: 0.9603\n",
            "Epoch 10/25\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.1285 - accuracy: 0.9625 - val_loss: 0.1316 - val_accuracy: 0.9619\n",
            "Epoch 11/25\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.1247 - accuracy: 0.9628 - val_loss: 0.1488 - val_accuracy: 0.9568\n",
            "Epoch 12/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1225 - accuracy: 0.9642 - val_loss: 0.1421 - val_accuracy: 0.9589\n",
            "Epoch 13/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1194 - accuracy: 0.9643 - val_loss: 0.1193 - val_accuracy: 0.9659\n",
            "Epoch 14/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1142 - accuracy: 0.9663 - val_loss: 0.1400 - val_accuracy: 0.9582\n",
            "Epoch 15/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1108 - accuracy: 0.9676 - val_loss: 0.1243 - val_accuracy: 0.9644\n",
            "Epoch 16/25\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.1078 - accuracy: 0.9675 - val_loss: 0.1104 - val_accuracy: 0.9663\n",
            "Epoch 17/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1037 - accuracy: 0.9700 - val_loss: 0.1162 - val_accuracy: 0.9663\n",
            "Epoch 18/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1023 - accuracy: 0.9694 - val_loss: 0.1348 - val_accuracy: 0.9614\n",
            "Epoch 19/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.1019 - accuracy: 0.9698 - val_loss: 0.1622 - val_accuracy: 0.9508\n",
            "Epoch 20/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.0981 - accuracy: 0.9710 - val_loss: 0.1149 - val_accuracy: 0.9645\n",
            "Epoch 21/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.0969 - accuracy: 0.9714 - val_loss: 0.1073 - val_accuracy: 0.9673\n",
            "Epoch 22/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.0952 - accuracy: 0.9721 - val_loss: 0.1050 - val_accuracy: 0.9677\n",
            "Epoch 23/25\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.0951 - accuracy: 0.9721 - val_loss: 0.1076 - val_accuracy: 0.9688\n",
            "Epoch 24/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.0924 - accuracy: 0.9718 - val_loss: 0.1150 - val_accuracy: 0.9643\n",
            "Epoch 25/25\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.0905 - accuracy: 0.9730 - val_loss: 0.0982 - val_accuracy: 0.9707\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 3.5483 - accuracy: 0.1135\n",
            "Accuracy: 0.11349999904632568\n"
          ]
        }
      ],
      "source": [
        "rows, col = 28, 28\n",
        "input_shape = (1, rows, col)\n",
        "epochs = 25\n",
        "verbose = 1\n",
        "optimizer = Adam()\n",
        "model = get_model2(input_shape, num_classes)\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.fit(x_train, Y_train, batch_size=64, epochs=epochs, validation_split=0.2)\n",
        "result = model.evaluate(x_test, Y_test, verbose=verbose)\n",
        "print('Accuracy:', result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS8PaQbWW9Am"
      },
      "source": [
        "#Model 3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7a849OZW4JG",
        "outputId": "8b9f677f-f522-4c26-85f6-15f44ba7bf81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_93 (Conv2D)          (None, 1, 28, 3)          759       \n",
            "                                                                 \n",
            " conv2d_94 (Conv2D)          (None, 1, 28, 4)          112       \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 1, 14, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 1, 14, 5)          185       \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 1, 14, 6)          276       \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 1, 7, 6)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 1, 7, 7)           385       \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 1, 7, 8)           512       \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 1, 4, 8)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 1, 4, 9)           657       \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 1, 4, 10)          820       \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 1, 2, 10)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 1, 2, 11)          1001      \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 1, 2, 12)          1200      \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 24)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                250       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,157\n",
            "Trainable params: 6,157\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.9712 - accuracy: 0.6702 - val_loss: 0.3658 - val_accuracy: 0.8907\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.3505 - accuracy: 0.8941 - val_loss: 0.2823 - val_accuracy: 0.9126\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2908 - accuracy: 0.9119 - val_loss: 0.2953 - val_accuracy: 0.9143\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2519 - accuracy: 0.9229 - val_loss: 0.2541 - val_accuracy: 0.9274\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.2253 - accuracy: 0.9318 - val_loss: 0.2375 - val_accuracy: 0.9268\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2072 - accuracy: 0.9371 - val_loss: 0.2224 - val_accuracy: 0.9365\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1934 - accuracy: 0.9412 - val_loss: 0.2228 - val_accuracy: 0.9350\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1821 - accuracy: 0.9456 - val_loss: 0.1750 - val_accuracy: 0.9494\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1735 - accuracy: 0.9473 - val_loss: 0.2080 - val_accuracy: 0.9365\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1678 - accuracy: 0.9491 - val_loss: 0.1737 - val_accuracy: 0.9520\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 2.2669 - accuracy: 0.1868\n",
            "Accuracy: 0.1868000030517578\n"
          ]
        }
      ],
      "source": [
        "rows, col = 28, 28\n",
        "input_shape = (1, rows, col)\n",
        "epochs = 10\n",
        "verbose = 1\n",
        "optimizer = SGD()\n",
        "model = get_model3(input_shape, num_classes)\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.fit(x_train, Y_train, batch_size=64, epochs=epochs, validation_split=0.2)\n",
        "result = model.evaluate(x_test, Y_test, verbose=verbose)\n",
        "print('Accuracy:', result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iVJeOuHuSRj"
      },
      "source": [
        "#**Question 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BHLMGtUVuXIY"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.datasets import cifar10 \n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "import numpy as np\n",
        "\n",
        "#the ConvNet\n",
        "@staticmethod\n",
        "def build(input_shape, classes):\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Conv2D(6, kernel_size=5, padding=\"same\", input_shape=input_shape),\n",
        "            layers.Activation(\"relu\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "            layers.Conv2D(16, kernel_size=5, padding=\"same\"),\n",
        "            layers.Activation(\"relu\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "            layers.Conv2D(120, kernel_size=5, padding=\"same\"),\n",
        "            layers.Activation(\"relu\"),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(84),\n",
        "            layers.Activation(\"relu\"),\n",
        "            layers.Dense(classes, activation=\"softmax\")\n",
        "        ]\n",
        "    )\n",
        "        \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06QK911z1i8U",
        "outputId": "4f0ad683-e89d-48b9-d5ae-27a975bb7032"
      },
      "outputs": [],
      "source": [
        "epochs = 25\n",
        "batch_size = 128\n",
        "verbose = 1\n",
        "optimizer = Adam()\n",
        "num_classes = 10\n",
        "input_shape = (32,32,3)\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "goTdLVgO3Q_U"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255 \n",
        "num_classes = 10\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir0vbqD8kpgm"
      },
      "source": [
        "#1.\tWhat is the effect of learning rate on the training process? Which performed best?  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBVA7uxUkyo1",
        "outputId": "9737b8e6-5a2a-4299-b5f2-fcd0bf57799f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 227.0962 - accuracy: 0.0995 - val_loss: 2.3061 - val_accuracy: 0.1022\n",
            "Epoch 2/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3077 - accuracy: 0.0986 - val_loss: 2.3063 - val_accuracy: 0.0997\n",
            "Epoch 3/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3084 - accuracy: 0.1014 - val_loss: 2.3079 - val_accuracy: 0.0977\n",
            "Epoch 4/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3079 - accuracy: 0.1027 - val_loss: 2.3104 - val_accuracy: 0.1014\n",
            "Epoch 5/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3092 - accuracy: 0.0984 - val_loss: 2.3066 - val_accuracy: 0.1016\n",
            "Epoch 6/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3080 - accuracy: 0.1014 - val_loss: 2.3044 - val_accuracy: 0.1014\n",
            "Epoch 7/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3092 - accuracy: 0.1004 - val_loss: 2.3053 - val_accuracy: 0.1003\n",
            "Epoch 8/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3096 - accuracy: 0.1016 - val_loss: 2.3100 - val_accuracy: 0.1003\n",
            "Epoch 9/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3083 - accuracy: 0.0996 - val_loss: 2.3097 - val_accuracy: 0.0980\n",
            "Epoch 10/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3098 - accuracy: 0.0987 - val_loss: 2.3061 - val_accuracy: 0.0980\n",
            "Epoch 11/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3081 - accuracy: 0.1002 - val_loss: 2.3060 - val_accuracy: 0.0997\n",
            "Epoch 12/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3090 - accuracy: 0.1007 - val_loss: 2.3214 - val_accuracy: 0.1025\n",
            "Epoch 13/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 2.3099 - accuracy: 0.0995 - val_loss: 2.3138 - val_accuracy: 0.1016\n",
            "Epoch 14/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 2.3081 - accuracy: 0.0998 - val_loss: 2.3093 - val_accuracy: 0.1014\n",
            "Epoch 15/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 2.3084 - accuracy: 0.0972 - val_loss: 2.3106 - val_accuracy: 0.0980\n",
            "Epoch 16/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3093 - accuracy: 0.0988 - val_loss: 2.3138 - val_accuracy: 0.1014\n",
            "Epoch 17/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3092 - accuracy: 0.1019 - val_loss: 2.3039 - val_accuracy: 0.0980\n",
            "Epoch 18/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3082 - accuracy: 0.1009 - val_loss: 2.3089 - val_accuracy: 0.1014\n",
            "Epoch 19/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3083 - accuracy: 0.1012 - val_loss: 2.3081 - val_accuracy: 0.0977\n",
            "Epoch 20/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3094 - accuracy: 0.0985 - val_loss: 2.3090 - val_accuracy: 0.1014\n",
            "Epoch 21/25\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 2.3101 - accuracy: 0.0996 - val_loss: 2.3071 - val_accuracy: 0.1025\n",
            "Epoch 22/25\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 2.3088 - accuracy: 0.0992 - val_loss: 2.3070 - val_accuracy: 0.1003\n",
            "Epoch 23/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 2.3103 - accuracy: 0.0969 - val_loss: 2.3117 - val_accuracy: 0.1014\n",
            "Epoch 24/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 2.3078 - accuracy: 0.0994 - val_loss: 2.3066 - val_accuracy: 0.1014\n",
            "Epoch 25/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 2.3091 - accuracy: 0.0997 - val_loss: 2.3057 - val_accuracy: 0.1025\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3069 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "313/313 [==============================] - 16s 49ms/step - loss: 2.3151 - accuracy: 0.1000 - val_loss: 2.3029 - val_accuracy: 0.0997\n",
            "Epoch 2/25\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 2.3033 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.1025\n",
            "Epoch 3/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3033 - accuracy: 0.0987 - val_loss: 2.3031 - val_accuracy: 0.1014\n",
            "Epoch 4/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3030 - accuracy: 0.1005 - val_loss: 2.3029 - val_accuracy: 0.1016\n",
            "Epoch 5/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3035 - accuracy: 0.0970 - val_loss: 2.3033 - val_accuracy: 0.1014\n",
            "Epoch 6/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3034 - accuracy: 0.0962 - val_loss: 2.3038 - val_accuracy: 0.0952\n",
            "Epoch 7/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3036 - accuracy: 0.0970 - val_loss: 2.3031 - val_accuracy: 0.0952\n",
            "Epoch 8/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3034 - accuracy: 0.0990 - val_loss: 2.3031 - val_accuracy: 0.1016\n",
            "Epoch 9/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3033 - accuracy: 0.0986 - val_loss: 2.3032 - val_accuracy: 0.1014\n",
            "Epoch 10/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 2.3033 - accuracy: 0.1008 - val_loss: 2.3034 - val_accuracy: 0.1025\n",
            "Epoch 11/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 2.3034 - accuracy: 0.0982 - val_loss: 2.3038 - val_accuracy: 0.1025\n",
            "Epoch 12/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3033 - accuracy: 0.0968 - val_loss: 2.3029 - val_accuracy: 0.1014\n",
            "Epoch 13/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3033 - accuracy: 0.0978 - val_loss: 2.3037 - val_accuracy: 0.0977\n",
            "Epoch 14/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3033 - accuracy: 0.1012 - val_loss: 2.3033 - val_accuracy: 0.1014\n",
            "Epoch 15/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3033 - accuracy: 0.0982 - val_loss: 2.3030 - val_accuracy: 0.1014\n",
            "Epoch 16/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3034 - accuracy: 0.0979 - val_loss: 2.3028 - val_accuracy: 0.1003\n",
            "Epoch 17/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3033 - accuracy: 0.1016 - val_loss: 2.3033 - val_accuracy: 0.1014\n",
            "Epoch 18/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3033 - accuracy: 0.1011 - val_loss: 2.3033 - val_accuracy: 0.0977\n",
            "Epoch 19/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3033 - accuracy: 0.1006 - val_loss: 2.3029 - val_accuracy: 0.1014\n",
            "Epoch 20/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 2.3034 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1014\n",
            "Epoch 21/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3034 - accuracy: 0.0976 - val_loss: 2.3033 - val_accuracy: 0.1016\n",
            "Epoch 22/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3035 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
            "Epoch 23/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3034 - accuracy: 0.1006 - val_loss: 2.3033 - val_accuracy: 0.1016\n",
            "Epoch 24/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3033 - accuracy: 0.1010 - val_loss: 2.3032 - val_accuracy: 0.1016\n",
            "Epoch 25/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3033 - accuracy: 0.0992 - val_loss: 2.3029 - val_accuracy: 0.1003\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3030 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "313/313 [==============================] - 16s 48ms/step - loss: 1.6557 - accuracy: 0.3958 - val_loss: 1.4788 - val_accuracy: 0.4685\n",
            "Epoch 2/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 1.2907 - accuracy: 0.5429 - val_loss: 1.2356 - val_accuracy: 0.5597\n",
            "Epoch 3/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 1.1389 - accuracy: 0.5989 - val_loss: 1.1271 - val_accuracy: 0.5978\n",
            "Epoch 4/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 1.0208 - accuracy: 0.6412 - val_loss: 1.0718 - val_accuracy: 0.6231\n",
            "Epoch 5/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.9260 - accuracy: 0.6736 - val_loss: 1.0306 - val_accuracy: 0.6385\n",
            "Epoch 6/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.8404 - accuracy: 0.7060 - val_loss: 1.0081 - val_accuracy: 0.6514\n",
            "Epoch 7/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.7615 - accuracy: 0.7330 - val_loss: 1.0099 - val_accuracy: 0.6548\n",
            "Epoch 8/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.6764 - accuracy: 0.7628 - val_loss: 0.9905 - val_accuracy: 0.6701\n",
            "Epoch 9/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.6018 - accuracy: 0.7918 - val_loss: 1.0349 - val_accuracy: 0.6600\n",
            "Epoch 10/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.5273 - accuracy: 0.8164 - val_loss: 1.0847 - val_accuracy: 0.6587\n",
            "Epoch 11/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.4490 - accuracy: 0.8439 - val_loss: 1.1610 - val_accuracy: 0.6660\n",
            "Epoch 12/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.3765 - accuracy: 0.8695 - val_loss: 1.1803 - val_accuracy: 0.6662\n",
            "Epoch 13/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.3115 - accuracy: 0.8926 - val_loss: 1.3075 - val_accuracy: 0.6548\n",
            "Epoch 14/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.2572 - accuracy: 0.9100 - val_loss: 1.4202 - val_accuracy: 0.6602\n",
            "Epoch 15/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.2136 - accuracy: 0.9263 - val_loss: 1.5105 - val_accuracy: 0.6522\n",
            "Epoch 16/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.1768 - accuracy: 0.9407 - val_loss: 1.6980 - val_accuracy: 0.6442\n",
            "Epoch 17/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.1393 - accuracy: 0.9537 - val_loss: 1.7580 - val_accuracy: 0.6522\n",
            "Epoch 18/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.1257 - accuracy: 0.9568 - val_loss: 1.8573 - val_accuracy: 0.6492\n",
            "Epoch 19/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.1073 - accuracy: 0.9633 - val_loss: 2.0578 - val_accuracy: 0.6377\n",
            "Epoch 20/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.0894 - accuracy: 0.9698 - val_loss: 2.1744 - val_accuracy: 0.6532\n",
            "Epoch 21/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.0740 - accuracy: 0.9751 - val_loss: 2.2446 - val_accuracy: 0.6548\n",
            "Epoch 22/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.1154 - accuracy: 0.9599 - val_loss: 2.2498 - val_accuracy: 0.6478\n",
            "Epoch 23/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.0774 - accuracy: 0.9737 - val_loss: 2.3534 - val_accuracy: 0.6491\n",
            "Epoch 24/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 0.0753 - accuracy: 0.9739 - val_loss: 2.4333 - val_accuracy: 0.6444\n",
            "Epoch 25/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.0776 - accuracy: 0.9734 - val_loss: 2.5529 - val_accuracy: 0.6457\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.5552 - accuracy: 0.6379\n",
            "[0.0996749997138977, 0.09915000200271606, 0.9733999967575073]\n",
            "[0.10000000149011612, 0.10000000149011612, 0.6378999948501587]\n"
          ]
        }
      ],
      "source": [
        "lr_test_result = []\n",
        "lr_result = []\n",
        "for lr in [0.1,0.01,0.25,0.5,0.001]:\n",
        "\t\tmodel = build(input_shape=input_shape, classes=num_classes)\n",
        "\t\tmodel.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
        "\t\thistory = model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_split=0.2)\n",
        "\t\tresult = model.evaluate(test_images, test_labels, verbose=verbose)\n",
        "\t\tlr_test_result.append(result[1])\n",
        "\t\tlr_result.append(history.history['accuracy'][-1])\n",
        "print(lr_result)\n",
        "print(lr_test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPjJifE7r-ro"
      },
      "source": [
        "#2.\tWhat is the effect of batch_size size on the training process? Which performed best?  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqRvL2kRrrUq",
        "outputId": "dd56222b-fe6e-41ef-861f-75f5d484db9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 24.5857 - accuracy: 0.0995 - val_loss: 2.3257 - val_accuracy: 0.0952\n",
            "Epoch 2/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3280 - accuracy: 0.1010 - val_loss: 2.3278 - val_accuracy: 0.1003\n",
            "Epoch 3/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3289 - accuracy: 0.0981 - val_loss: 2.3303 - val_accuracy: 0.0980\n",
            "Epoch 4/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3284 - accuracy: 0.1026 - val_loss: 2.3356 - val_accuracy: 0.0980\n",
            "Epoch 5/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3291 - accuracy: 0.0979 - val_loss: 2.3366 - val_accuracy: 0.0977\n",
            "Epoch 6/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3288 - accuracy: 0.0998 - val_loss: 2.3595 - val_accuracy: 0.1022\n",
            "Epoch 7/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3292 - accuracy: 0.0997 - val_loss: 2.3375 - val_accuracy: 0.1016\n",
            "Epoch 8/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3284 - accuracy: 0.1017 - val_loss: 2.3190 - val_accuracy: 0.1003\n",
            "Epoch 9/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3275 - accuracy: 0.1022 - val_loss: 2.3282 - val_accuracy: 0.1022\n",
            "Epoch 10/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3284 - accuracy: 0.1025 - val_loss: 2.3133 - val_accuracy: 0.0997\n",
            "Epoch 11/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3276 - accuracy: 0.0989 - val_loss: 2.3317 - val_accuracy: 0.0997\n",
            "Epoch 12/25\n",
            "5000/5000 [==============================] - 40s 8ms/step - loss: 2.3294 - accuracy: 0.0989 - val_loss: 2.3137 - val_accuracy: 0.0952\n",
            "Epoch 13/25\n",
            "5000/5000 [==============================] - 40s 8ms/step - loss: 2.3289 - accuracy: 0.1006 - val_loss: 2.3191 - val_accuracy: 0.1014\n",
            "Epoch 14/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3298 - accuracy: 0.1001 - val_loss: 2.3354 - val_accuracy: 0.1014\n",
            "Epoch 15/25\n",
            "5000/5000 [==============================] - 42s 8ms/step - loss: 2.3295 - accuracy: 0.0979 - val_loss: 2.3426 - val_accuracy: 0.1014\n",
            "Epoch 16/25\n",
            "5000/5000 [==============================] - 50s 10ms/step - loss: 2.3297 - accuracy: 0.0981 - val_loss: 2.3459 - val_accuracy: 0.1014\n",
            "Epoch 17/25\n",
            "5000/5000 [==============================] - 50s 10ms/step - loss: 2.3295 - accuracy: 0.0975 - val_loss: 2.3344 - val_accuracy: 0.0952\n",
            "Epoch 18/25\n",
            "5000/5000 [==============================] - 50s 10ms/step - loss: 2.3290 - accuracy: 0.0989 - val_loss: 2.3329 - val_accuracy: 0.0977\n",
            "Epoch 19/25\n",
            "5000/5000 [==============================] - 45s 9ms/step - loss: 2.3288 - accuracy: 0.0997 - val_loss: 2.3170 - val_accuracy: 0.1025\n",
            "Epoch 20/25\n",
            "5000/5000 [==============================] - 42s 8ms/step - loss: 2.3283 - accuracy: 0.1020 - val_loss: 2.3213 - val_accuracy: 0.1016\n",
            "Epoch 21/25\n",
            "5000/5000 [==============================] - 42s 8ms/step - loss: 2.3290 - accuracy: 0.1010 - val_loss: 2.3173 - val_accuracy: 0.0980\n",
            "Epoch 22/25\n",
            "5000/5000 [==============================] - 42s 8ms/step - loss: 2.3289 - accuracy: 0.0955 - val_loss: 2.3261 - val_accuracy: 0.1014\n",
            "Epoch 23/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3299 - accuracy: 0.0963 - val_loss: 2.3396 - val_accuracy: 0.0997\n",
            "Epoch 24/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3302 - accuracy: 0.0994 - val_loss: 2.3234 - val_accuracy: 0.1025\n",
            "Epoch 25/25\n",
            "5000/5000 [==============================] - 41s 8ms/step - loss: 2.3284 - accuracy: 0.1002 - val_loss: 2.3198 - val_accuracy: 0.1003\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3201 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 25.4604 - accuracy: 0.0984 - val_loss: 2.3128 - val_accuracy: 0.0997\n",
            "Epoch 2/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3217 - accuracy: 0.0999 - val_loss: 2.3126 - val_accuracy: 0.1025\n",
            "Epoch 3/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3227 - accuracy: 0.0985 - val_loss: 2.3311 - val_accuracy: 0.1003\n",
            "Epoch 4/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3202 - accuracy: 0.1012 - val_loss: 2.3145 - val_accuracy: 0.1022\n",
            "Epoch 5/25\n",
            "2500/2500 [==============================] - 29s 12ms/step - loss: 2.3211 - accuracy: 0.1022 - val_loss: 2.3079 - val_accuracy: 0.1025\n",
            "Epoch 6/25\n",
            "2500/2500 [==============================] - 29s 12ms/step - loss: 2.3212 - accuracy: 0.0989 - val_loss: 2.3157 - val_accuracy: 0.1003\n",
            "Epoch 7/25\n",
            "2500/2500 [==============================] - 29s 12ms/step - loss: 2.3199 - accuracy: 0.1016 - val_loss: 2.3128 - val_accuracy: 0.0997\n",
            "Epoch 8/25\n",
            "2500/2500 [==============================] - 29s 12ms/step - loss: 2.3206 - accuracy: 0.1006 - val_loss: 2.3150 - val_accuracy: 0.1016\n",
            "Epoch 9/25\n",
            "2500/2500 [==============================] - 29s 12ms/step - loss: 2.3206 - accuracy: 0.1000 - val_loss: 2.3150 - val_accuracy: 0.1025\n",
            "Epoch 10/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3207 - accuracy: 0.1019 - val_loss: 2.3242 - val_accuracy: 0.1014\n",
            "Epoch 11/25\n",
            "2500/2500 [==============================] - 27s 11ms/step - loss: 2.3213 - accuracy: 0.0993 - val_loss: 2.3192 - val_accuracy: 0.1014\n",
            "Epoch 12/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3221 - accuracy: 0.1010 - val_loss: 2.3218 - val_accuracy: 0.0977\n",
            "Epoch 13/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3195 - accuracy: 0.1020 - val_loss: 2.3097 - val_accuracy: 0.0952\n",
            "Epoch 14/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3211 - accuracy: 0.1011 - val_loss: 2.3167 - val_accuracy: 0.1025\n",
            "Epoch 15/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3214 - accuracy: 0.0976 - val_loss: 2.3216 - val_accuracy: 0.0952\n",
            "Epoch 16/25\n",
            "2500/2500 [==============================] - 29s 12ms/step - loss: 2.3209 - accuracy: 0.0998 - val_loss: 2.3096 - val_accuracy: 0.1014\n",
            "Epoch 17/25\n",
            "2500/2500 [==============================] - 29s 12ms/step - loss: 2.3200 - accuracy: 0.0997 - val_loss: 2.3232 - val_accuracy: 0.0977\n",
            "Epoch 18/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3213 - accuracy: 0.1003 - val_loss: 2.3185 - val_accuracy: 0.0977\n",
            "Epoch 19/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3224 - accuracy: 0.0994 - val_loss: 2.3189 - val_accuracy: 0.1025\n",
            "Epoch 20/25\n",
            "2500/2500 [==============================] - 28s 11ms/step - loss: 2.3204 - accuracy: 0.0999 - val_loss: 2.3199 - val_accuracy: 0.0980\n",
            "Epoch 21/25\n",
            "2500/2500 [==============================] - 29s 12ms/step - loss: 2.3212 - accuracy: 0.0995 - val_loss: 2.3298 - val_accuracy: 0.1014\n",
            "Epoch 22/25\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 2.3199 - accuracy: 0.1004 - val_loss: 2.3138 - val_accuracy: 0.0997\n",
            "Epoch 23/25\n",
            "2500/2500 [==============================] - 31s 12ms/step - loss: 2.3204 - accuracy: 0.1001 - val_loss: 2.3412 - val_accuracy: 0.0952\n",
            "Epoch 24/25\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 2.3218 - accuracy: 0.1008 - val_loss: 2.3192 - val_accuracy: 0.1016\n",
            "Epoch 25/25\n",
            "2500/2500 [==============================] - 30s 12ms/step - loss: 2.3220 - accuracy: 0.0989 - val_loss: 2.3192 - val_accuracy: 0.0952\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3180 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 25.7122 - accuracy: 0.1007 - val_loss: 2.3272 - val_accuracy: 0.0952\n",
            "Epoch 2/25\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 2.3152 - accuracy: 0.0979 - val_loss: 2.3066 - val_accuracy: 0.1016\n",
            "Epoch 3/25\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 2.3154 - accuracy: 0.0979 - val_loss: 2.3078 - val_accuracy: 0.0980\n",
            "Epoch 4/25\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 2.3146 - accuracy: 0.1038 - val_loss: 2.3154 - val_accuracy: 0.1022\n",
            "Epoch 5/25\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 2.3151 - accuracy: 0.1007 - val_loss: 2.3097 - val_accuracy: 0.0997\n",
            "Epoch 6/25\n",
            "1250/1250 [==============================] - 21s 17ms/step - loss: 2.3162 - accuracy: 0.0987 - val_loss: 2.3114 - val_accuracy: 0.0977\n",
            "Epoch 7/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3146 - accuracy: 0.1016 - val_loss: 2.3277 - val_accuracy: 0.0952\n",
            "Epoch 8/25\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 2.3146 - accuracy: 0.1023 - val_loss: 2.3328 - val_accuracy: 0.1016\n",
            "Epoch 9/25\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 2.3151 - accuracy: 0.1026 - val_loss: 2.3203 - val_accuracy: 0.1014\n",
            "Epoch 10/25\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 2.3151 - accuracy: 0.0975 - val_loss: 2.3222 - val_accuracy: 0.1014\n",
            "Epoch 11/25\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 2.3152 - accuracy: 0.1002 - val_loss: 2.3289 - val_accuracy: 0.1022\n",
            "Epoch 12/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3153 - accuracy: 0.0994 - val_loss: 2.3159 - val_accuracy: 0.1003\n",
            "Epoch 13/25\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 2.3141 - accuracy: 0.1028 - val_loss: 2.3125 - val_accuracy: 0.0977\n",
            "Epoch 14/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3153 - accuracy: 0.0969 - val_loss: 2.3153 - val_accuracy: 0.0997\n",
            "Epoch 15/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3151 - accuracy: 0.1001 - val_loss: 2.3160 - val_accuracy: 0.1022\n",
            "Epoch 16/25\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 2.3158 - accuracy: 0.0981 - val_loss: 2.3169 - val_accuracy: 0.1003\n",
            "Epoch 17/25\n",
            "1250/1250 [==============================] - 23s 18ms/step - loss: 2.3157 - accuracy: 0.0975 - val_loss: 2.3224 - val_accuracy: 0.0977\n",
            "Epoch 18/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3151 - accuracy: 0.1007 - val_loss: 2.3193 - val_accuracy: 0.1014\n",
            "Epoch 19/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3166 - accuracy: 0.0975 - val_loss: 2.3096 - val_accuracy: 0.1016\n",
            "Epoch 20/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3156 - accuracy: 0.0991 - val_loss: 2.3254 - val_accuracy: 0.1016\n",
            "Epoch 21/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3142 - accuracy: 0.1021 - val_loss: 2.3117 - val_accuracy: 0.0997\n",
            "Epoch 22/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3152 - accuracy: 0.1010 - val_loss: 2.3169 - val_accuracy: 0.1016\n",
            "Epoch 23/25\n",
            "1250/1250 [==============================] - 22s 18ms/step - loss: 2.3162 - accuracy: 0.0989 - val_loss: 2.3093 - val_accuracy: 0.0997\n",
            "Epoch 24/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3161 - accuracy: 0.0995 - val_loss: 2.3148 - val_accuracy: 0.0980\n",
            "Epoch 25/25\n",
            "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3153 - accuracy: 0.0991 - val_loss: 2.3235 - val_accuracy: 0.1016\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3223 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "625/625 [==============================] - 20s 31ms/step - loss: 16.7989 - accuracy: 0.0998 - val_loss: 2.3092 - val_accuracy: 0.1022\n",
            "Epoch 2/25\n",
            "625/625 [==============================] - 19s 31ms/step - loss: 2.3113 - accuracy: 0.1015 - val_loss: 2.3118 - val_accuracy: 0.0997\n",
            "Epoch 3/25\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3112 - accuracy: 0.0991 - val_loss: 2.3118 - val_accuracy: 0.1014\n",
            "Epoch 4/25\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3121 - accuracy: 0.0990 - val_loss: 2.3135 - val_accuracy: 0.0977\n",
            "Epoch 5/25\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3119 - accuracy: 0.0948 - val_loss: 2.3127 - val_accuracy: 0.1014\n",
            "Epoch 6/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3119 - accuracy: 0.0993 - val_loss: 2.3080 - val_accuracy: 0.1025\n",
            "Epoch 7/25\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3114 - accuracy: 0.0969 - val_loss: 2.3072 - val_accuracy: 0.1014\n",
            "Epoch 8/25\n",
            "625/625 [==============================] - 18s 30ms/step - loss: 2.3115 - accuracy: 0.1010 - val_loss: 2.3083 - val_accuracy: 0.1014\n",
            "Epoch 9/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3108 - accuracy: 0.0993 - val_loss: 2.3100 - val_accuracy: 0.0977\n",
            "Epoch 10/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3115 - accuracy: 0.1006 - val_loss: 2.3087 - val_accuracy: 0.1022\n",
            "Epoch 11/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3118 - accuracy: 0.0994 - val_loss: 2.3125 - val_accuracy: 0.1014\n",
            "Epoch 12/25\n",
            "625/625 [==============================] - 18s 30ms/step - loss: 2.3112 - accuracy: 0.0987 - val_loss: 2.3109 - val_accuracy: 0.1025\n",
            "Epoch 13/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3110 - accuracy: 0.1018 - val_loss: 2.3092 - val_accuracy: 0.0952\n",
            "Epoch 14/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3119 - accuracy: 0.0992 - val_loss: 2.3059 - val_accuracy: 0.1014\n",
            "Epoch 15/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3110 - accuracy: 0.1015 - val_loss: 2.3133 - val_accuracy: 0.0997\n",
            "Epoch 16/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3116 - accuracy: 0.1006 - val_loss: 2.3120 - val_accuracy: 0.1022\n",
            "Epoch 17/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3115 - accuracy: 0.0997 - val_loss: 2.3116 - val_accuracy: 0.0952\n",
            "Epoch 18/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3113 - accuracy: 0.0993 - val_loss: 2.3224 - val_accuracy: 0.1014\n",
            "Epoch 19/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3116 - accuracy: 0.0984 - val_loss: 2.3110 - val_accuracy: 0.0980\n",
            "Epoch 20/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3115 - accuracy: 0.0985 - val_loss: 2.3111 - val_accuracy: 0.1003\n",
            "Epoch 21/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3115 - accuracy: 0.1005 - val_loss: 2.3201 - val_accuracy: 0.0997\n",
            "Epoch 22/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3113 - accuracy: 0.1028 - val_loss: 2.3079 - val_accuracy: 0.1014\n",
            "Epoch 23/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3120 - accuracy: 0.0985 - val_loss: 2.3133 - val_accuracy: 0.1003\n",
            "Epoch 24/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3121 - accuracy: 0.0984 - val_loss: 2.3131 - val_accuracy: 0.1025\n",
            "Epoch 25/25\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3123 - accuracy: 0.0987 - val_loss: 2.3186 - val_accuracy: 0.1016\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3189 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "313/313 [==============================] - 16s 49ms/step - loss: 77.0857 - accuracy: 0.1027 - val_loss: 2.3055 - val_accuracy: 0.1003\n",
            "Epoch 2/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3082 - accuracy: 0.1010 - val_loss: 2.3045 - val_accuracy: 0.1022\n",
            "Epoch 3/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3086 - accuracy: 0.0982 - val_loss: 2.3069 - val_accuracy: 0.1016\n",
            "Epoch 4/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3080 - accuracy: 0.1008 - val_loss: 2.3070 - val_accuracy: 0.0952\n",
            "Epoch 5/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 2.3086 - accuracy: 0.1020 - val_loss: 2.3062 - val_accuracy: 0.0977\n",
            "Epoch 6/25\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 2.3090 - accuracy: 0.1001 - val_loss: 2.3087 - val_accuracy: 0.1016\n",
            "Epoch 7/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 2.3095 - accuracy: 0.1002 - val_loss: 2.3124 - val_accuracy: 0.0997\n",
            "Epoch 8/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3083 - accuracy: 0.1023 - val_loss: 2.3147 - val_accuracy: 0.0980\n",
            "Epoch 9/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3084 - accuracy: 0.1017 - val_loss: 2.3071 - val_accuracy: 0.0997\n",
            "Epoch 10/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3087 - accuracy: 0.0985 - val_loss: 2.3064 - val_accuracy: 0.1003\n",
            "Epoch 11/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 2.3094 - accuracy: 0.1002 - val_loss: 2.3133 - val_accuracy: 0.0997\n",
            "Epoch 12/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3081 - accuracy: 0.1011 - val_loss: 2.3077 - val_accuracy: 0.0977\n",
            "Epoch 13/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3104 - accuracy: 0.1003 - val_loss: 2.3073 - val_accuracy: 0.1003\n",
            "Epoch 14/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3094 - accuracy: 0.0980 - val_loss: 2.3069 - val_accuracy: 0.0997\n",
            "Epoch 15/25\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 2.3085 - accuracy: 0.0980 - val_loss: 2.3066 - val_accuracy: 0.1016\n",
            "Epoch 16/25\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 2.3092 - accuracy: 0.1012 - val_loss: 2.3106 - val_accuracy: 0.0977\n",
            "Epoch 17/25\n",
            "313/313 [==============================] - 15s 50ms/step - loss: 2.3088 - accuracy: 0.0988 - val_loss: 2.3070 - val_accuracy: 0.0977\n",
            "Epoch 18/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 2.3081 - accuracy: 0.0995 - val_loss: 2.3123 - val_accuracy: 0.1003\n",
            "Epoch 19/25\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 2.3087 - accuracy: 0.1008 - val_loss: 2.3066 - val_accuracy: 0.0952\n",
            "Epoch 20/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3088 - accuracy: 0.0993 - val_loss: 2.3067 - val_accuracy: 0.0997\n",
            "Epoch 21/25\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 2.3083 - accuracy: 0.1014 - val_loss: 2.3089 - val_accuracy: 0.0997\n",
            "Epoch 22/25\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 2.3085 - accuracy: 0.0996 - val_loss: 2.3106 - val_accuracy: 0.1014\n",
            "Epoch 23/25\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 2.3099 - accuracy: 0.0991 - val_loss: 2.3055 - val_accuracy: 0.1025\n",
            "Epoch 24/25\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 2.3086 - accuracy: 0.0989 - val_loss: 2.3104 - val_accuracy: 0.1016\n",
            "Epoch 25/25\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 2.3086 - accuracy: 0.1013 - val_loss: 2.3080 - val_accuracy: 0.1022\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3079 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "157/157 [==============================] - 14s 89ms/step - loss: 81.3444 - accuracy: 0.0993 - val_loss: 2.3057 - val_accuracy: 0.0997\n",
            "Epoch 2/25\n",
            "157/157 [==============================] - 14s 87ms/step - loss: 2.3060 - accuracy: 0.0984 - val_loss: 2.3082 - val_accuracy: 0.0952\n",
            "Epoch 3/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3053 - accuracy: 0.0979 - val_loss: 2.3048 - val_accuracy: 0.1003\n",
            "Epoch 4/25\n",
            "157/157 [==============================] - 14s 87ms/step - loss: 2.3060 - accuracy: 0.0974 - val_loss: 2.3034 - val_accuracy: 0.1003\n",
            "Epoch 5/25\n",
            "157/157 [==============================] - 14s 88ms/step - loss: 2.3061 - accuracy: 0.1007 - val_loss: 2.3048 - val_accuracy: 0.1025\n",
            "Epoch 6/25\n",
            "157/157 [==============================] - 14s 86ms/step - loss: 2.3068 - accuracy: 0.1015 - val_loss: 2.3057 - val_accuracy: 0.0977\n",
            "Epoch 7/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3062 - accuracy: 0.1006 - val_loss: 2.3102 - val_accuracy: 0.0980\n",
            "Epoch 8/25\n",
            "157/157 [==============================] - 13s 86ms/step - loss: 2.3061 - accuracy: 0.1005 - val_loss: 2.3078 - val_accuracy: 0.0997\n",
            "Epoch 9/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3067 - accuracy: 0.0967 - val_loss: 2.3069 - val_accuracy: 0.0997\n",
            "Epoch 10/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3069 - accuracy: 0.0996 - val_loss: 2.3042 - val_accuracy: 0.1014\n",
            "Epoch 11/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3068 - accuracy: 0.0999 - val_loss: 2.3060 - val_accuracy: 0.0952\n",
            "Epoch 12/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3061 - accuracy: 0.1021 - val_loss: 2.3057 - val_accuracy: 0.1003\n",
            "Epoch 13/25\n",
            "157/157 [==============================] - 14s 87ms/step - loss: 2.3069 - accuracy: 0.0980 - val_loss: 2.3090 - val_accuracy: 0.0980\n",
            "Epoch 14/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3078 - accuracy: 0.0986 - val_loss: 2.3099 - val_accuracy: 0.0980\n",
            "Epoch 15/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3061 - accuracy: 0.1033 - val_loss: 2.3078 - val_accuracy: 0.1022\n",
            "Epoch 16/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3071 - accuracy: 0.1011 - val_loss: 2.3063 - val_accuracy: 0.0952\n",
            "Epoch 17/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3079 - accuracy: 0.0999 - val_loss: 2.3114 - val_accuracy: 0.0977\n",
            "Epoch 18/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3063 - accuracy: 0.1018 - val_loss: 2.3041 - val_accuracy: 0.0997\n",
            "Epoch 19/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3070 - accuracy: 0.0998 - val_loss: 2.3053 - val_accuracy: 0.1014\n",
            "Epoch 20/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3065 - accuracy: 0.0997 - val_loss: 2.3054 - val_accuracy: 0.1016\n",
            "Epoch 21/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3063 - accuracy: 0.0984 - val_loss: 2.3058 - val_accuracy: 0.1025\n",
            "Epoch 22/25\n",
            "157/157 [==============================] - 13s 84ms/step - loss: 2.3071 - accuracy: 0.0992 - val_loss: 2.3065 - val_accuracy: 0.1016\n",
            "Epoch 23/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3063 - accuracy: 0.1001 - val_loss: 2.3049 - val_accuracy: 0.0977\n",
            "Epoch 24/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3067 - accuracy: 0.0991 - val_loss: 2.3113 - val_accuracy: 0.1025\n",
            "Epoch 25/25\n",
            "157/157 [==============================] - 13s 85ms/step - loss: 2.3077 - accuracy: 0.0967 - val_loss: 2.3072 - val_accuracy: 0.1016\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3071 - accuracy: 0.1000\n",
            "[0.1002499982714653, 0.09892500191926956, 0.09910000115633011, 0.09870000183582306, 0.10125000029802322, 0.09674999862909317]\n",
            "[0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612]\n"
          ]
        }
      ],
      "source": [
        "bs_result = []\n",
        "bs_test_result = []\n",
        "for i in [8,16,32,64,128,256]:\n",
        "    model = build(input_shape=input_shape, classes=num_classes)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.1),\n",
        "    metrics=[\"accuracy\"])\n",
        "    history = model.fit(train_images, train_labels,\n",
        "    batch_size=i, epochs=epochs,\n",
        "    verbose=verbose,  validation_split=0.2)\n",
        "    result = model.evaluate(test_images, test_labels, verbose=verbose)\n",
        "    bs_result.append(history.history['accuracy'][-1])\n",
        "    bs_test_result.append(result[1])\n",
        "print(bs_result)\n",
        "print(bs_test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNYFxq2gvg5y"
      },
      "source": [
        "#3. Try different hyperparameters to obtain the best accuracy on the test set. What is your best performance and what were the hyperparameters?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omjiXxWsvnvg",
        "outputId": "19ab8d99-d94d-4ea7-f425-f5d37751060b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 25.2105 - accuracy: 0.0991 - val_loss: 2.3096 - val_accuracy: 0.1014\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 2.3116 - accuracy: 0.1003 - val_loss: 2.3111 - val_accuracy: 0.0980\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3120 - accuracy: 0.0971 - val_loss: 2.3181 - val_accuracy: 0.1003\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3109 - accuracy: 0.1010 - val_loss: 2.3158 - val_accuracy: 0.1025\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3127 - accuracy: 0.0992 - val_loss: 2.3084 - val_accuracy: 0.0980\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3077 - accuracy: 0.1000\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 146.9606 - accuracy: 0.0980 - val_loss: 2.3160 - val_accuracy: 0.1025\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 2.3117 - accuracy: 0.1003 - val_loss: 2.3078 - val_accuracy: 0.1014\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 2.3120 - accuracy: 0.1018 - val_loss: 2.3094 - val_accuracy: 0.0952\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 2.3115 - accuracy: 0.1007 - val_loss: 2.3083 - val_accuracy: 0.1014\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 2.3117 - accuracy: 0.1001 - val_loss: 2.3046 - val_accuracy: 0.1014\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 2.3128 - accuracy: 0.0982 - val_loss: 2.3079 - val_accuracy: 0.1022\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 2.3107 - accuracy: 0.1000 - val_loss: 2.3050 - val_accuracy: 0.1022\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 2.3116 - accuracy: 0.1004 - val_loss: 2.3124 - val_accuracy: 0.1022\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 2.3112 - accuracy: 0.1008 - val_loss: 2.3104 - val_accuracy: 0.0977\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 2.3115 - accuracy: 0.1019 - val_loss: 2.3098 - val_accuracy: 0.1014\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3095 - accuracy: 0.1000\n",
            "Epoch 1/15\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 75.8316 - accuracy: 0.1038 - val_loss: 2.3091 - val_accuracy: 0.0997\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 18s 30ms/step - loss: 2.3120 - accuracy: 0.1007 - val_loss: 2.3144 - val_accuracy: 0.0952\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3117 - accuracy: 0.0984 - val_loss: 2.3169 - val_accuracy: 0.0977\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3111 - accuracy: 0.1016 - val_loss: 2.3126 - val_accuracy: 0.0980\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3116 - accuracy: 0.0979 - val_loss: 2.3136 - val_accuracy: 0.0997\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3119 - accuracy: 0.1004 - val_loss: 2.3099 - val_accuracy: 0.0980\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3127 - accuracy: 0.0976 - val_loss: 2.3068 - val_accuracy: 0.1014\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3114 - accuracy: 0.0984 - val_loss: 2.3112 - val_accuracy: 0.0952\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3116 - accuracy: 0.1015 - val_loss: 2.3118 - val_accuracy: 0.0980\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3119 - accuracy: 0.0970 - val_loss: 2.3079 - val_accuracy: 0.0997\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 18s 30ms/step - loss: 2.3111 - accuracy: 0.1015 - val_loss: 2.3110 - val_accuracy: 0.0980\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 18s 30ms/step - loss: 2.3114 - accuracy: 0.1026 - val_loss: 2.3134 - val_accuracy: 0.1014\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3116 - accuracy: 0.1000 - val_loss: 2.3097 - val_accuracy: 0.1022\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 2.3113 - accuracy: 0.1010 - val_loss: 2.3146 - val_accuracy: 0.1025\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 2.3118 - accuracy: 0.0992 - val_loss: 2.3099 - val_accuracy: 0.0952\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3087 - accuracy: 0.1000\n",
            "Epoch 1/20\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 45.8498 - accuracy: 0.0987 - val_loss: 2.3107 - val_accuracy: 0.1016\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3106 - accuracy: 0.0988 - val_loss: 2.3086 - val_accuracy: 0.1003\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3119 - accuracy: 0.1008 - val_loss: 2.3143 - val_accuracy: 0.1016\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3117 - accuracy: 0.0975 - val_loss: 2.3088 - val_accuracy: 0.0977\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3116 - accuracy: 0.1006 - val_loss: 2.3161 - val_accuracy: 0.1014\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3123 - accuracy: 0.1006 - val_loss: 2.3083 - val_accuracy: 0.0980\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3114 - accuracy: 0.1001 - val_loss: 2.3143 - val_accuracy: 0.0977\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3118 - accuracy: 0.0979 - val_loss: 2.3106 - val_accuracy: 0.0997\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3112 - accuracy: 0.1005 - val_loss: 2.3095 - val_accuracy: 0.1014\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 2.3115 - accuracy: 0.1007 - val_loss: 2.3196 - val_accuracy: 0.0952\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 19s 31ms/step - loss: 2.3119 - accuracy: 0.0981 - val_loss: 2.3099 - val_accuracy: 0.0952\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3120 - accuracy: 0.1004 - val_loss: 2.3130 - val_accuracy: 0.0977\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3117 - accuracy: 0.0985 - val_loss: 2.3060 - val_accuracy: 0.0997\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3115 - accuracy: 0.1016 - val_loss: 2.3203 - val_accuracy: 0.0977\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3121 - accuracy: 0.0988 - val_loss: 2.3109 - val_accuracy: 0.1016\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3113 - accuracy: 0.0987 - val_loss: 2.3129 - val_accuracy: 0.1022\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3105 - accuracy: 0.1006 - val_loss: 2.3122 - val_accuracy: 0.1016\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3117 - accuracy: 0.0964 - val_loss: 2.3089 - val_accuracy: 0.1022\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3114 - accuracy: 0.1005 - val_loss: 2.3071 - val_accuracy: 0.1022\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 2.3119 - accuracy: 0.0985 - val_loss: 2.3078 - val_accuracy: 0.0980\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 2.3069 - accuracy: 0.1000\n",
            "[0.09917499870061874, 0.10189999639987946, 0.09915000200271606, 0.09849999845027924]\n",
            "[0.10000000149011612, 0.10000000149011612, 0.10000000149011612, 0.10000000149011612]\n"
          ]
        }
      ],
      "source": [
        "epo_result = []\n",
        "epo_test_result = []\n",
        "for i in [5,10,15,20]:\n",
        "    # initialize the optimizer and model\n",
        "    model = build(input_shape=input_shape, classes=num_classes)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.1),\n",
        "    metrics=[\"accuracy\"])\n",
        "    history = model.fit(train_images, train_labels,\n",
        "    batch_size=64, epochs=i,\n",
        "    verbose=verbose,  validation_split=0.2)\n",
        "    result = model.evaluate(test_images, test_labels, verbose=verbose)\n",
        "    epo_result.append(history.history['accuracy'][-1])\n",
        "    epo_test_result.append(result[1])\n",
        "print(epo_result)\n",
        "print(epo_test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pJgrhTwvugq"
      },
      "source": [
        "#4. Implement an equivalent feed forward network for the same task with each hidden layer containing the same number of neurons as the number of parameters in each convolution layer. Use the Adam optimizer to train your network on the CIFAR-10 dataset for a fixed set of 25 epochs. Compare its performance with your LeNet implementation based on the following questions:\n",
        "#a. What is its performance?\n",
        "#b. How many parameters are there in this network compared to the LeNet implementation? Are they worth it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yBtoCuDhvrCH"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "@staticmethod\n",
        "def model_4(input_shape, classes):\n",
        "        model = keras.Sequential(\n",
        "            [\n",
        "                layers.Conv2D(64, kernel_size=5, padding=\"same\",input_shape=input_shape, activation=\"relu\"),\n",
        "                layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "                layers.Conv2D(64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
        "                layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "                layers.Conv2D(64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
        "                layers.Flatten(),\n",
        "                layers.Dense(64, activation=\"relu\"),\n",
        "                layers.Dense(classes, activation=\"softmax\")\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8_msVcwv38p",
        "outputId": "faea5d03-e144-4a9a-b001-ab364c1cff1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 3013.7437 - accuracy: 0.1012 - val_loss: 2.3118 - val_accuracy: 0.0977\n",
            "Epoch 2/25\n",
            "625/625 [==============================] - 74s 119ms/step - loss: 2.3108 - accuracy: 0.0988 - val_loss: 2.3059 - val_accuracy: 0.0997\n",
            "Epoch 3/25\n",
            "625/625 [==============================] - 74s 119ms/step - loss: 2.3101 - accuracy: 0.1006 - val_loss: 2.3066 - val_accuracy: 0.0952\n",
            "Epoch 4/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3104 - accuracy: 0.1010 - val_loss: 2.3131 - val_accuracy: 0.1014\n",
            "Epoch 5/25\n",
            "625/625 [==============================] - 73s 116ms/step - loss: 2.3118 - accuracy: 0.1014 - val_loss: 2.3068 - val_accuracy: 0.0997\n",
            "Epoch 6/25\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 2.3123 - accuracy: 0.0981 - val_loss: 2.3055 - val_accuracy: 0.1025\n",
            "Epoch 7/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3113 - accuracy: 0.1011 - val_loss: 2.3124 - val_accuracy: 0.1014\n",
            "Epoch 8/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3113 - accuracy: 0.1002 - val_loss: 2.3081 - val_accuracy: 0.0997\n",
            "Epoch 9/25\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 2.3116 - accuracy: 0.1003 - val_loss: 2.3142 - val_accuracy: 0.1022\n",
            "Epoch 10/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3109 - accuracy: 0.1025 - val_loss: 2.3059 - val_accuracy: 0.1022\n",
            "Epoch 11/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3111 - accuracy: 0.1017 - val_loss: 2.3069 - val_accuracy: 0.0980\n",
            "Epoch 12/25\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 2.3113 - accuracy: 0.1008 - val_loss: 2.3047 - val_accuracy: 0.1003\n",
            "Epoch 13/25\n",
            "625/625 [==============================] - 70s 113ms/step - loss: 2.3109 - accuracy: 0.1006 - val_loss: 2.3110 - val_accuracy: 0.1022\n",
            "Epoch 14/25\n",
            "625/625 [==============================] - 71s 114ms/step - loss: 2.3116 - accuracy: 0.0980 - val_loss: 2.3077 - val_accuracy: 0.1014\n",
            "Epoch 15/25\n",
            "625/625 [==============================] - 72s 116ms/step - loss: 2.3124 - accuracy: 0.0969 - val_loss: 2.3183 - val_accuracy: 0.1014\n",
            "Epoch 16/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3125 - accuracy: 0.0985 - val_loss: 2.3064 - val_accuracy: 0.0980\n",
            "Epoch 17/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3113 - accuracy: 0.0991 - val_loss: 2.3156 - val_accuracy: 0.1003\n",
            "Epoch 18/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3110 - accuracy: 0.1010 - val_loss: 2.3131 - val_accuracy: 0.0997\n",
            "Epoch 19/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3121 - accuracy: 0.0999 - val_loss: 2.3130 - val_accuracy: 0.0952\n",
            "Epoch 20/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3119 - accuracy: 0.0986 - val_loss: 2.3050 - val_accuracy: 0.0997\n",
            "Epoch 21/25\n",
            "625/625 [==============================] - 73s 117ms/step - loss: 2.3117 - accuracy: 0.1000 - val_loss: 2.3074 - val_accuracy: 0.1025\n",
            "Epoch 22/25\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 2.3112 - accuracy: 0.1010 - val_loss: 2.3154 - val_accuracy: 0.0952\n",
            "Epoch 23/25\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 2.3118 - accuracy: 0.0948 - val_loss: 2.3101 - val_accuracy: 0.1014\n",
            "Epoch 24/25\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 2.3107 - accuracy: 0.1010 - val_loss: 2.3055 - val_accuracy: 0.1025\n",
            "Epoch 25/25\n",
            "625/625 [==============================] - 75s 120ms/step - loss: 2.3119 - accuracy: 0.1019 - val_loss: 2.3202 - val_accuracy: 0.1014\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 2.3208 - accuracy: 0.1000\n",
            "Training accuracy 0.1018500030040741\n",
            "Accuracy 0.10000000149011612\n"
          ]
        }
      ],
      "source": [
        "model = model_4(input_shape=input_shape, classes=num_classes)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.1),\n",
        "metrics=[\"accuracy\"])\n",
        "history = model.fit(train_images, train_labels,\n",
        "batch_size=64, epochs=25,\n",
        "verbose=verbose,  validation_split=0.2)\n",
        "result = model.evaluate(test_images, test_labels, verbose=verbose)\n",
        "print(\"Training accuracy\", history.history['accuracy'][-1])\n",
        "print(\"Accuracy\", result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJmvq89p0bwz"
      },
      "source": [
        "#**Question 3**\n",
        "\n",
        "Consider the below matrices as input (X) and convolutional kernel f. Consider that the depth of the input is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BZT4A2lYyhMg"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([[[7], [5], [0], [0], [3], [2]],\n",
        "                   [[6], [4], [5], [1], [4], [8]],\n",
        "                   [[9], [0], [2], [2], [5], [4]],\n",
        "                   [[6], [3], [4], [7], [9], [8]],\n",
        "                   [[5], [7], [5], [6], [9], [0]],\n",
        "                   [[7], [9], [0], [8], [2], [3]]])\n",
        "x = x.astype('float32') \n",
        "\n",
        "f = np.array([[1, 0, -1],\n",
        "                   [2, 0, -2],\n",
        "                   [1, 0, -1]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ6HFowo0gcE"
      },
      "source": [
        "#1.\tWhat are the dimensions of the input and the kernel (or filter)? How many parameters are there in the kernel f? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymvPN4LA0ktA",
        "outputId": "e339485a-b8d4-4db2-f21d-6da2367d7dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension of input 6\n",
            "Dimension of filter 3\n",
            "Parameters in kernal 9\n"
          ]
        }
      ],
      "source": [
        "print(\"Dimension of input\",x.shape[0])\n",
        "print(\"Dimension of filter\",f.shape[0])\n",
        "print(\"Parameters in kernal\", f.shape[0]*f.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3mKWERn1SSs"
      },
      "source": [
        "#2.\tWhat is the output activation map when you apply the convolutional operation using the filter f on the input X without padding? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hQHMg1bxq54",
        "outputId": "1d03511b-2f3f-4f9c-9185-b0b5e1cfd4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 91ms/step\n",
            "[[[[ 16.]\n",
            "   [  9.]\n",
            "   [ -4.]\n",
            "   [-18.]]\n",
            "\n",
            "  [[ 17.]\n",
            "   [ -5.]\n",
            "   [-10.]\n",
            "   [-12.]]\n",
            "\n",
            "  [[ 11.]\n",
            "   [ -9.]\n",
            "   [-17.]\n",
            "   [  2.]]\n",
            "\n",
            "  [[  9.]\n",
            "   [ -1.]\n",
            "   [-15.]\n",
            "   [ 16.]]]]\n"
          ]
        }
      ],
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "from keras import Input, layers\n",
        "from keras.models import Model\n",
        "\n",
        "def my_filter(shape, dtype=None):\n",
        "\n",
        "    f = np.array([\n",
        "            [[[1]], [[0]], [[-1]]],\n",
        "            [[[2]], [[0]], [[-2]]],\n",
        "            [[[1]], [[0]], [[-1]]]\n",
        "        ])\n",
        "    assert f.shape == shape\n",
        "    return K.variable(f, dtype='float32')\n",
        "X = np.array([\n",
        "                   [[7], [5], [0], [0], [3], [2]],\n",
        "                   [[6], [4], [5], [1], [4], [8]],\n",
        "                   [[9], [0], [2], [2], [5], [4]],\n",
        "                   [[6], [3], [4], [7], [9], [8]],\n",
        "                   [[5], [7], [5], [6], [9], [0]],\n",
        "                   [[7], [9], [0], [8], [2], [3]]])\n",
        "\n",
        "X = X.reshape((1, 6, 6, 1))\n",
        "def build_model():\n",
        "    input_tensor = Input(shape=(6,6,1))\n",
        "\n",
        "    x = layers.Conv2D(filters=1, \n",
        "                      kernel_size = 3,\n",
        "                      kernel_initializer=my_filter,\n",
        "                      strides=1, \n",
        "                      padding='valid') (input_tensor)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=x)\n",
        "    return model\n",
        "model = build_model()\n",
        "out = model.predict(X)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnaaqLkHxs9s"
      },
      "source": [
        "#3.\tWhat is the output when you apply a max-pooling operation on the output from the previous question? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5VVw4t8u31X",
        "outputId": "e244d457-4c81-4dee-dcae-7d470d593713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "[[17.  9.]\n",
            " [17. 16.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential \n",
        "from keras.layers import MaxPooling2D \n",
        "\n",
        "model = Sequential( \n",
        "    [MaxPooling2D(pool_size = 3, strides = 1)]) \n",
        "output = model.predict(out)   \n",
        "output = np.squeeze(output) \n",
        "print(output) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJYYru9CXsoV",
        "outputId": "53acb1a3-d12e-491e-9e3b-d45bf91cf4dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_134 (Conv2D)         (None, 32, 32, 6)         456       \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 32, 32, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_63 (MaxPoolin  (None, 16, 16, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_135 (Conv2D)         (None, 16, 16, 16)        2416      \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 16, 16, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_64 (MaxPoolin  (None, 8, 8, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_136 (Conv2D)         (None, 8, 8, 120)         48120     \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 8, 8, 120)         0         \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 7680)              0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 84)                645204    \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 84)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build(input_shape=input_shape, classes=num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Question 1\n",
        "1.) Learning Rate = 0.1, batch_size =256, epochs = 25, accuracy 0.113\n",
        "2.) Learning Rate = 0.1, batch_size =64, epochs = 25, accuracy 0.113\n",
        "3.) Learning Rate = 0.1, batch_size =64, epochs = 25, accuracy 0.186\n",
        "\n",
        "Question 2\n",
        "1.) Learning rate = [0.1,0.01,0.25,0.5,0.001], batch size = 128, epochs = 25, Accuracy decresed with increasing leraning rate, best performing = 0.01\n",
        "2.) Batch Size = [8,16,32,64,128,256], Learning rate = 0.1, epochs = 25, Accuracy varied with batch size but not definitevly, best performing = 64,128\n",
        "2.) epochs = [5,10,15,20], Learning rate = 0.1, batch size = 64, Accuracy varied with epochs but not definitevly, best performing = 10\n",
        "4.)a.)Accuracy = 0.100\n",
        "b.) There were more hyperparameters comparatively, no it took nore time to execute relatively.\n",
        "\n",
        "References:\n",
        "1.) https://keras.io/examples/vision/mnist_convnet/\n",
        "2.) https://keras.io/api/datasets/mnist/#load_data-function\n",
        "3.) https://keras.io/api/datasets/cifar10/\n",
        "4.) https://github.com/sushantkumar-estech/LeNet-CNN-for-CIFAR-10-Classification-Dataset/blob/master/LeNet_Convolutional_Neural_Network_for_CIFAR_10_Classification_Dataset.ipynb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
